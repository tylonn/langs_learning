{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Python - Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Python Data Model\n",
    "The first thing one should know when understanding advanced concepts in Python is that every item in Python is an object, which functions as an abstraction for data, encapsulating state (data) and behavior (methods). On top of that, these objects are characterized by having an `identity`, a `type` and a `value`. This characterization is important because it allows Python to manage an object's lifecycle throughout program execution. Let's dive a little deeper into how Python uses these items to manage its objects.\n",
    "\n",
    "#### ID\n",
    "In Python, an object's identity never changes once it has been created. This identity is the memory address of the object. In this scenario, the `is` operator is the most suitable way to compare the identity of two objects instead of `==`.  It is worth mentioning that the *id* sometimes is obtained through some optimizations, as listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139683335127408\n",
      "139683335127312\n",
      "139683335127312\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "first_value = 5\n",
    "print(id(first_value))\n",
    "\n",
    "second_value = 2\n",
    "print(id(second_value))\n",
    "\n",
    "third_value = 2\n",
    "print(id(third_value))\n",
    "\n",
    "print(first_value is second_value)\n",
    "print(second_value is third_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern observed above only refer to numbers between -5 and 256. This is because Python stores small integers in a cache due to performance reasons. In those cases, Python pre-allocates the integer objects created and reuses them as an attempt to save memory.\n",
    "When two variables are created and they have the same value, Python pre-allocates this value ensuring that both variables refers to the same object in memory. Whereas for values outside this range, Python allocates a new object in memory each time that an integer variable is created, as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2817949078032\n",
      "2817949078064\n",
      "2817949077968\n",
      "2817949078352\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "first_value = 256\n",
    "print(id(first_value))\n",
    "\n",
    "second_value = 256\n",
    "print(id(second_value))\n",
    "\n",
    "third_value = -5\n",
    "print(id(third_value))\n",
    "\n",
    "fourth_value = -5\n",
    "print(id(fourth_value))\n",
    "\n",
    "print(first_value is second_value)\n",
    "print(third_value is fourth_value)\n",
    "\n",
    "print(15 * \"-\")\n",
    "\n",
    "first_value = 257\n",
    "print(id(first_value))\n",
    "\n",
    "second_value = 257\n",
    "print(id(second_value))\n",
    "\n",
    "third_value = -6\n",
    "print(id(third_value))\n",
    "\n",
    "fourth_value = -6\n",
    "print(id(fourth_value))\n",
    "\n",
    "print(first_value is second_value)\n",
    "print(third_value is fourth_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This behavior extend in certain level to strings and do not is extended to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2817949077392\n",
      "2817949077360\n",
      "2817949076880\n",
      "2817949077328\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "first_value = 2.56\n",
    "print(id(first_value))\n",
    "\n",
    "second_value = 2.56\n",
    "print(id(second_value))\n",
    "\n",
    "third_value = -5.0\n",
    "print(id(third_value))\n",
    "\n",
    "fourth_value = -5.0\n",
    "print(id(fourth_value))\n",
    "\n",
    "print(first_value is second_value)\n",
    "print(third_value is fourth_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140002182303664\n",
      "140002182303664\n",
      "140002182303280\n",
      "140002182307952\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "first_value = \"Hello_world\"\n",
    "print(id(first_value))\n",
    "\n",
    "second_value = \"Hello_world\"\n",
    "print(id(second_value))\n",
    "\n",
    "third_value = \"Hello, world!\"\n",
    "print(id(third_value))\n",
    "\n",
    "fourth_value = \"Hello, world!\"\n",
    "print(id(fourth_value))\n",
    "\n",
    "print(first_value is second_value)\n",
    "print(third_value is fourth_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For strings, Python performs string interning selectively. This means that string literals that look like identifiers are typically interned automatically. Interning is a type of caching that applies to specific object instances and refers to Python reusing the string object instead of creating a new one every time the same string literal is used.\n",
    "\n",
    "In a broader sense, Python can perform some optimizations with immutable objects that may seem to have the same interning performed with integers and strings, but that are actually compiler optimizations. In these optimizations, the interpreter understands that some immutable objects are the same if they are placed in different parts of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140568893257856\n",
      "140568892681856\n",
      "140568892797920\n",
      "140568892800160\n",
      "False\n",
      "False\n",
      "140568893131712\n",
      "140568893131712\n",
      "Is a equals b? The answer is: True\n"
     ]
    }
   ],
   "source": [
    "first_value = (1, 2, 3)\n",
    "print(id(first_value))\n",
    "\n",
    "second_value = (1, 2, 3)\n",
    "print(id(second_value))\n",
    "\n",
    "third_value = {1, 2, 3}\n",
    "print(id(third_value))\n",
    "\n",
    "fourth_value = {1, 2, 3}\n",
    "print(id(fourth_value))\n",
    "\n",
    "print(first_value is second_value)\n",
    "print(third_value is fourth_value)\n",
    "\n",
    "\n",
    "# Optimizations occurs here:\n",
    "def test_id():\n",
    "    a = (1, 2, 3)\n",
    "    b = (1, 2, 3)\n",
    "\n",
    "    print(id(a))\n",
    "    print(id(b))\n",
    "\n",
    "    print(f\"Is a equals b? The answer is: {a is b}\")\n",
    "\n",
    "\n",
    "test_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above optimization occurs only in the function namespace due to its restrictive nature. The function namespace is a confined and well-defined scope of code analysis. Therefore, allowing the compiler to make some optimizations more aggressive when compared to its application at the global namespace (which is more unpredictable and dynamic).  \n",
    "\n",
    "The *id* function has some uses that are related to scenarios where the the management of object identities is necessary (e.g debbuging). These situations generally involve identifying duplicates, performing caching/memoization, and implementing low-level optimizations. Although it has its uses, the *id* function is rarely applied in Python codebases and can be replaced in most cases by using the `is` operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type  \n",
    "The object's type defines which operations can be applied to the object itself. It also defines the possible values that an object of the referred type can have. We can check the type of an object using the  `type()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'list'>\n",
      "<class 'type'>\n",
      "<class 'type'>\n"
     ]
    }
   ],
   "source": [
    "a = 5\n",
    "print(type(a))\n",
    "b = [1, 2, 3]\n",
    "print(type(b))\n",
    "print(type(type))\n",
    "print(type(object))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `type` object is a metaclass (a class of a class) and also a function that returns the type of an object. In this sense, `type` is an instance of itself, forming a recursive loop and is considered the foundational class of the Python language, because it is the class from which all other classes are derived, directly or indirectly. \n",
    "\n",
    "This self-referential characteristic of the `type` metaclass is what allows it to act as a foundation for all classes. Python allows us to create metaclasses for our classes and these metaclasses are also derived from the `type` class.  \n",
    "\n",
    "It is important to note that `type` is the default metaclass in Python which defines how a class behaves, allowing the customization of class creation, modification, and deletion. Furthermore, it also can be thought of as classes of classes (a class is an instance of its metaclass). In this scenario, every class in Python is an instance of `type`, even itself.  \n",
    "\n",
    "Another important concept in Python is base classes. This category of objects forms the classes that other classes inherit from. In Python, the `object` class is the one inherited by all new-style classes (with all its attributes and methods).  \n",
    "\n",
    "Besides getting the type of an object, the `type` function can also be used to create a class dynamically. This feature has some interesting applications, as demonstrated below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "25\n",
      "5\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "MyDynamicClass = type(\n",
    "    \"MyDynamicClass\",  # Name\n",
    "    (object,),  # Bases\n",
    "    {\"x\": 5, \"y\": 10, \"z\": staticmethod(lambda x: x * x)},  # Dict\n",
    ")\n",
    "print(MyDynamicClass.x)\n",
    "print(MyDynamicClass.z(5))\n",
    "\n",
    "instance = MyDynamicClass()\n",
    "\n",
    "print(instance.x)\n",
    "print(instance.z(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of dynamically created classes follows a clear pattern that is mostly suited to situations when the properties, methods, or base classes of the Python's objects are determined by external factors only known at runtime, such as user input, configuration data, or external schemas. This approach fits properly in scenarios where static class creation would lead to excessive code duplication or complexity.  \n",
    "A helpful way of thinking in terms of using this approach is to evaluate if the behavior of a class is dependent on conditions only known at runtime, requires class dynamic generation/modification, aims to avoid code duplication, or allows end users to modify/extend the system without altering the core codebase.   \n",
    "Although very useful in certain situations, the use of type in this manner adds a significant level of complexity to the code, requiring its use to always be well-considered and accounting for possible trade-offs.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some use cases that cover the vast majority of situations where creating a class dynamically could be helpful. One such use case is when there's a requirement to create a class at runtime that should contain type hints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.SubClass"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Type, cast\n",
    "\n",
    "\n",
    "class BaseClass:\n",
    "    pass\n",
    "\n",
    "\n",
    "# The cast function cast a value to a type, returning it unchanged. It is only useful for type-checkers\n",
    "# because it signals that the type has the designated value.\n",
    "cast(Type[BaseClass], type(\"SubClass\", (BaseClass,), {}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to dynamically create a class with slots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<member 'a' of 'MyClass' objects>\n"
     ]
    }
   ],
   "source": [
    "MyClass = type(\"MyClass\", (), {\"__slots__\": (\"a\", \"b\")})\n",
    "print(MyClass.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slots allow for the explicit specification of which instance attributes an object instances are expected to have. This results in faster attribute access and reduced memory usage. The memory savings occur because instances do not use a dynamic dictionary (`__dict__`) for attribute storage; instead, they use a fixed-sized array, which is less memory-intensive than a dictionary. Additionally, accessing attributes stored in `__slots__` follows a more direct memory access pattern, resulting in less indirection compared to a dictionary. Moreover, using `__slots__` ensures that instances cannot access attributes not listed in it.\n",
    "\n",
    "It's worth mentioning that dynamic attribute assignment is still possible when using slots, although some of the memory size benefits are lost. This can be achieved by including `\"__dict__\"` in the `__slots__` definition, allowing for dynamic attributes in addition to those specified. The use of slots requires careful consideration due to the changes in class behavior it introduces.\n",
    "\n",
    "More information about __slots__ can be found [here](https://stackoverflow.com/questions/472000/usage-of-slots).  \n",
    "\n",
    "It is also possible to pass dunder methods dynamically (as seen above) to classes created dynamically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 and A\n"
     ]
    }
   ],
   "source": [
    "def init(self):\n",
    "    self.x = 5\n",
    "    self.y = \"A\"\n",
    "\n",
    "\n",
    "MyClass = type(\"MyClass\", (), {\"__init__\": init})\n",
    "\n",
    "my_instance = MyClass()\n",
    "print(f\"{my_instance.x} and {my_instance.y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another pattern that could be useful is to create a class factory to generate classes automatically:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 and B\n"
     ]
    }
   ],
   "source": [
    "def class_builder(cls_name=\"MyClass\"):\n",
    "    # NOTE: it is possible to add a arg that map base classes\n",
    "    def init(self):\n",
    "        self.x = 25\n",
    "        self.y = \"B\"\n",
    "\n",
    "    return type(cls_name, (), {\"__init__\": init})\n",
    "\n",
    "\n",
    "MyClass = class_builder()\n",
    "my_instance = MyClass()\n",
    "print(f\"{my_instance.x} and {my_instance.y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of pattern is useful for serialization and deserialiaztion of objects. The use of this type of pattern in general also follows the recommendations mentioned previously, spetially in situations where the data is known only at runtime, as mentioned [here](https://ctskennerton.github.io/2021/11/24/dynamic-types-in-python./)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another situation that is useful being aware of is the possibility for passing default arguments to a subclass created dynamically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subclass created and my name is John\n"
     ]
    }
   ],
   "source": [
    "class BaseClass:\n",
    "    def __init_subclass__(cls, my_name):\n",
    "        print(f\"Subclass created and my name is {my_name}\")\n",
    "        # super().__init_subclass__() Needed only in case of multiple inheritance\n",
    "\n",
    "\n",
    "MyDynamicSubClass = type(\"MyDynamicSubClass\", (BaseClass,), {}, my_name=\"John\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When is this pattern useful?\n",
    "\n",
    " - Runtime Configuration: When specific information is only available at runtime, allowing for dynamic class creation and customization.\n",
    "- Validation and Registration: For implementing checks and registering instances to ensure data integrity and uniqueness.\n",
    "- Default Data Provision: To pre-populate subclasses with relevant data based on their specific type or context.  \n",
    "\n",
    "Further information about `__init_subclass__` can be found [here](https://stackoverflow.com/questions/63473901/python-dynamically-create-class-while-providing-arguments-to-init-subclass)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another pattern useful for dynamic class creation from containers, like JSON, is to use a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burger with attributes {'aka': ['cheeseburger', 'hamburger']}\n",
      "fries with attributes {'aka': ['french fries', 'potatoes']}\n",
      "meal with attributes {'items': [{'name': 'burger', 'value': '<burger>'}, {'name': 'fries', 'value': '<fries>'}]}\n"
     ]
    }
   ],
   "source": [
    "my_json = {\n",
    "    \"stuff\": [\n",
    "        {\"name\": \"burger\", \"aka\": [\"cheeseburger\", \"hamburger\"]},\n",
    "        {\"name\": \"fries\", \"aka\": [\"french fries\", \"potatoes\"]},\n",
    "        {\n",
    "            \"name\": \"meal\",\n",
    "            \"items\": [\n",
    "                {\"name\": \"burger\", \"value\": \"<burger>\"},\n",
    "                {\"name\": \"fries\", \"value\": \"<fries>\"},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "class MenuItem:\n",
    "\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__} with attributes {self.__dict__}\"\n",
    "\n",
    "\n",
    "for d in my_json[\"stuff\"]:\n",
    "    name = d.pop(\"name\")\n",
    "    NewClass = type(name, (MenuItem,), d)\n",
    "    print(NewClass(**d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, type hints may be required during dynamic class creation. In sistuations like this the best approach is to leverage the use of duncer methods in association with the `type` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Some string', {'some_field': str})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_hints = {\"some_field\": str}\n",
    "MyClass = type(\n",
    "    \"MyClass\",\n",
    "    (),\n",
    "    {\n",
    "        \"__doc__\": \"Class created dynamically\",\n",
    "        \"__annotations__\": type_hints,\n",
    "        \"some_field\": \"Some string\",\n",
    "    },\n",
    ")\n",
    "new_instace = MyClass()\n",
    "new_instace.some_field, new_instace.__annotations__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beside the `type` function, Python also has as an alternative to class creation the `types.new_class` function. The class creation process through `types.new_class` is signficantly more flexible when compared to the base `type` as it provides a mechanism for directly dealing with metaclasses and also allows a `exec_body` to be executed in the namespace of the class being created. More about the use of this approach can be found [here](https://docs.python.org/3/library/types.html#dynamic-type-creation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value\n",
    "The value of a object can change or not. This capabilitie defines if a object is mutable or immutable. But immutability is a tricky concept because a immutable object can have a reference to a mutable one. So, in this scenario, the value of a immutable object `can change` when the mutable object its referes to change. In this sense immutability is different from having a unchangeable value. Altough, the `id` of the object do not tend to change, at least in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, [1, 2, 256])\n",
      "8893480\n",
      "140518044983424\n",
      "140518044832640\n",
      "(1, 2, [1, 2, (5545, 'my tuple')])\n",
      "140518079995392\n",
      "140518044983424\n",
      "140518044832640\n"
     ]
    }
   ],
   "source": [
    "num = 256\n",
    "lst = [1, 2, num]\n",
    "tpl = (1, 2, lst)\n",
    "print(tpl)\n",
    "print(id(num))\n",
    "print(id(lst))\n",
    "print(id(tpl))\n",
    "num = (5545, \"my tuple\")\n",
    "lst[2] = num\n",
    "print(tpl)\n",
    "print(id(num))\n",
    "print(id(lst))\n",
    "print(id(tpl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, the `id`s of lst and tpl did not changed because when a object is created in Python its id remains the same even after altering the value it is refering to.  \n",
    "One other important thing is that, for immutable types, operations that compute a new value may actually return a reference to any existing object `a = 1; b = 1` where a and b may referes to the same object, but in `c = []; d = []` is guaranteed that c and d refers to different objects.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structures\n",
    "We discussed about the fundamental rules that govern Python objects. A logical next step in learning programming is to understand how these building blocks and rules can be leveraged to create larger structures.\n",
    "Built-in Python sequences can be categorized as Container Sequences and Flat Sequences. The difference between these two is that the former can hold references to items of different types while the latter is a single object that can only store values of the same type in its memory space.  \n",
    "In general, Flat Sequences are more compact, although they are limited to holding only primitive types.  \n",
    "Every python object has header with metadata. For example, the a `float` has these fields:   \n",
    "- on_refcnt: the object's reference count   \n",
    "- ob_type: a pointer to the object's type   \n",
    "- ob_val: a C double holding the value of the float  \n",
    " \n",
    "And each one of these fields takes 8 bytes. For this reason, an array of floats is more compact than a tuple: the array is a single object holding the raw values of its items, while the tuple consists of several objects (the tuple itself and each object contained in it).  \n",
    "\n",
    "Let's deepen our understanding of this difference a little more with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of a tuple:\n",
      "getsizeof: 96\n",
      "asizeof: 264\n",
      "__________________________________________________\n",
      "                                                  \n",
      "The size of an array:\n",
      "getsizeof: 136\n",
      "asizeof: 136\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import array\n",
    "from pympler import asizeof\n",
    "\n",
    "print(\"The size of a tuple:\")\n",
    "\n",
    "print(f\"getsizeof: {sys.getsizeof(tuple([1.5, 2.1, 3.8, 4.8, 8.6, 4.9, 3.9]))}\")\n",
    "print(f\"asizeof: {asizeof.asizeof(tuple([1.5, 2.1, 3.8, 4.8, 8.6, 4.9, 3.9]))}\")\n",
    "\n",
    "print(50 * \"_\")\n",
    "print(50 * \" \")\n",
    "\n",
    "print(\"The size of an array:\")\n",
    "\n",
    "print(f'getsizeof: {sys.getsizeof(array.array(\"d\", [1.5, 2.1, 3.8, 4.8, 8.6, 4.9, 3.9]))}')\n",
    "print(f'asizeof: {asizeof.asizeof(array.array(\"d\", [1.5, 2.1, 3.8, 4.8, 8.6, 4.9, 3.9]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that an array occupies significantly less space than a tuple because it holds value directly rather than references, as mentioned previously.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Let's understand the difference between the two methods to measure the size of objects in Python.  \n",
    "\n",
    "In the code above we used two methods of calculating the size of a python object. `getsizeof` returns the size of the object passed to itself, whereas `asizeof` returns the size of the object passed to it but also the objects referenced within the complex object instance.   \n",
    "\n",
    "In general, `getsizeof` only reports the raw memory allocated (the header and its immediate contents) for the list's data and it is based on the interpreter's internal calculations.  \n",
    "Meanwhile, `asizeof` calculate this by recursively adding up the sizes of all objects after traversing the object's contents and examining the object attributes. `asizeof` also avoids calculating the size of the same object twice, if it is referenced more than once, by tracking of the objects IDs that it already visited by using a `set` or a similar mechanism that allows it to recognize already-measured objects.  \n",
    "\n",
    "It is important to note that it uses `getsizeof` to measure the size of the objects encountered and also accounts for the extra space allocated by container objects since some Python objects have over-allocation to optimize append operations, furthermore, it can detect1 shared objects, such as objects that are instances of classes with `__slots__` or some interned objects like strings.\n",
    "\n",
    "Fonts:  \n",
    "[One](hhttps://stackoverflow.com/questions/11301295/measure-object-size-accurately-in-python-sys-getsizeof-not-functioning)  \n",
    "[Two](https://stackoverflow.com/questions/34787327/pympler-asizeof-vs-sys-getsizeof)  \n",
    "\n",
    "Now, we will talk more about the most fundamental sequence types in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists, Generators, Tuples, Sets and, Dictionaries\n",
    "\n",
    "#### Lists\n",
    "Python has some commonly used built-in container types that are very handy and have a wide variety of use cases. The first of them, and perhaps the most used, is the `list`. Lists are present in pretty much everything Python touches due to their versatility. A notable example is list comprehensions (listcomp), which can be used for a wide range of situations. Two common patterns for using list comprehensions are replacing map and filter, and for Cartesian products, as demonstrated below. Using list comprehensions is a neat approach to reducing code complexity and can also be very useful when dealing with sorted lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cartesian Product:\n",
      "[('Urophylla', 80), ('Urophylla', 90), ('Urophylla', 89), ('Camaldulensis', 80), ('Camaldulensis', 90), ('Camaldulensis', 89), ('Citriodora', 80), ('Citriodora', 90), ('Citriodora', 89), ('Globulus', 80), ('Globulus', 90), ('Globulus', 89)]\n",
      "\n",
      "Sorted Cartesian Product:\n",
      "[('Urophylla', 90), ('Camaldulensis', 90), ('Citriodora', 90), ('Globulus', 90), ('Urophylla', 89), ('Camaldulensis', 89), ('Citriodora', 89), ('Globulus', 89), ('Urophylla', 80), ('Camaldulensis', 80), ('Citriodora', 80), ('Globulus', 80)]\n",
      "\n",
      "Filtered listcomp:\n",
      "['Citriodora', 'Globulus']\n"
     ]
    }
   ],
   "source": [
    "# Cartesian product\n",
    "species = [\"Urophylla\", \"Camaldulensis\", \"Citriodora\", \"Globulus\"]\n",
    "models = [80, 90, 89]\n",
    "\n",
    "print(\"Cartesian Product:\")\n",
    "print([(specie, model) for specie in species for model in models])\n",
    "print(\"\")\n",
    "\n",
    "# Sorted Cartesian Product\n",
    "print(\"Sorted Cartesian Product:\")\n",
    "print(sorted(\n",
    "    [(specie, model) for specie in species for model in models],\n",
    "    key=lambda model: model[1],\n",
    "    reverse=True,\n",
    "))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Filtered listcomp:\")\n",
    "print([specie for specie in species if specie not in [\"Urophylla\", \"Camaldulensis\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding with the discussion about other ways of creating sequences, let's talk a little about the Walrus Operator `:=`. This operator allows us to combine assignment and expression evaluation into a single operation. An interesting result of this is the possibility of avoiding code duplication, as shown below, which was common before the introduction of this operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List size is 4\n"
     ]
    }
   ],
   "source": [
    "my_list = [5, 6 , 8, 6]\n",
    "if (size := len(my_list)) > 3:\n",
    "    print(f\"List size is {size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0], [2, 2], [3, 6], [4, 12], [5, 20]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[y := x + 1, x * y] for x in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generators\n",
    "Generator Expressions (genexps) are an alternative to lists and can be used to initialize other types of sequences. The use of genexps provides a significant advantage when the goal is to reduce memory usage. The approach that generators use is fairly simple, yet very powerful: they do not produce any values until requested. In other words, a generator expression does not return the collection of data upon its creation. The \"forcing\" of item production occurs through features like loops, collection construction and calls to `next` on the generator object. However, it should be noted that once the generator object is used, its contents are no longer available, and the error `StopIteration` is raised when all its items have been consumed.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x7f8eaef617e0>\n",
      "Urophylla yields: 80\n",
      "Urophylla yields: 90\n",
      "Urophylla yields: 89\n",
      "Camaldulensis yields: 80\n",
      "Camaldulensis yields: 90\n",
      "Camaldulensis yields: 89\n",
      "Citriodora yields: 80\n",
      "Citriodora yields: 90\n",
      "Citriodora yields: 89\n",
      "['Urophylla yields: 80', 'Urophylla yields: 90', 'Urophylla yields: 89', 'Camaldulensis yields: 80', 'Camaldulensis yields: 90', 'Camaldulensis yields: 89', 'Citriodora yields: 80', 'Citriodora yields: 90', 'Citriodora yields: 89']\n",
      "{'Urophylla yields: 80', 'Camaldulensis yields: 90', 'Citriodora yields: 89', 'Camaldulensis yields: 89', 'Citriodora yields: 90', 'Citriodora yields: 80', 'Urophylla yields: 89', 'Camaldulensis yields: 80', 'Urophylla yields: 90'}\n"
     ]
    }
   ],
   "source": [
    "species = [\"Urophylla\", \"Camaldulensis\", \"Citriodora\"]\n",
    "models = [80, 90, 89]\n",
    "\n",
    "model_ranking = (\n",
    "    f\"{specie} yields: {model}\" for specie in species for model in models\n",
    ")\n",
    "# We see that this object is a generator object\n",
    "print(model_ranking)\n",
    "\n",
    "# Consuming the genexp\n",
    "for i in model_ranking:\n",
    "    print(i)\n",
    "\n",
    "# Creating a list and a set from a generator expression\n",
    "list_from_ge = list((f\"{specie} yields: {model}\" for specie in species for model in models))\n",
    "set_from_ge = set((f\"{specie} yields: {model}\" for specie in species for model in models))\n",
    "\n",
    "\n",
    "print(list_from_ge)\n",
    "print(set_from_ge)\n",
    "# A error arrisen when trying to use a generator object after the consuption of its items\n",
    "# next(model_ranking) raises StopIteration error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuples\n",
    "Tuples are quite similar to lists, so much so that people sometimes tend to call tuples \"immutable lists\". This does not do justice to tuples as they are also records without field names (a concept similar to tuple structs in Rust). Before we dive into tuples' superpowers, let's understand how they can be used [to store items more effectively than lists](https://stackoverflow.com/questions/68630/are-tuples-more-efficient-than-lists-in-python).  \n",
    "\n",
    "Tuples tend to be more efficient than lists in some aspects:\n",
    "\n",
    "1. Tuples can be constant folded: In Computer Science, constant folding refers to the process of recognizing and evaluating constant expressions at compile time rather than computing them at runtime. In Python, this process is used to recognize when a tuple contains only constants and optimize it by precomputing the tuple during compilation. In the example below, we can see that more steps are necessary to build a list because Python treats the entire tuple as a constant when it contains only constants. In this scenario, the immutable nature of tuples is leveraged to improve their creation performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0           RESUME                   0\n",
      "\n",
      "  1           RETURN_CONST             0 ((10, 'abc'))\n",
      "------------------------------------------------------------\n",
      "  0           RESUME                   0\n",
      "\n",
      "  1           LOAD_CONST               0 (10)\n",
      "              LOAD_CONST               1 ('abc')\n",
      "              BUILD_LIST               2\n",
      "              RETURN_VALUE\n"
     ]
    }
   ],
   "source": [
    "from dis import dis\n",
    "dis(compile(\"(10, 'abc')\", \"\", \"eval\"))\n",
    "\n",
    "print(60 * \"-\")\n",
    "\n",
    "dis(compile(\"[10, 'abc']\", '', 'eval'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tuples are not copied: Since tuples are immutable structures, they are not copied upon being passed as arguments to other tuples. In this case, Python recognizes that it is safe to reuse a tuple instead of creating a new one. Hence, calling a tuple on a tuple is faster and more efficient than calling a list on a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (10, 20, 30)\n",
    "b = tuple(a)\n",
    "a is b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [10, 20, 30]\n",
    "b = list(a)\n",
    "a is b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Tuples do not overallocate: Since tuples are immutable, their sizes are fixed. Therefore, it is not necessary to allocate extra memory to account for future item additions through `append()` calls. NOTE: although true, this is not particularly significant at the present moment. Looking at the results below, it is possible to observe that the differences are not drastic as they were once in previous Python versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000040, 2000056)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pympler import asizeof\n",
    "\n",
    "asizeof.asizeof(tuple(iter(range(50000)))), asizeof.asizeof(list(iter(range(50000))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Tuples refer directly to their elements: Tuples do not have the indirection layer found in lists, where they point to an array of pointers. Instead, they incorporate their references directly into the tuple object. Note that this holds slightly for indexing, but not as much for unpacking, and holds significantly for assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$python -m timeit -s 'a = (10, 20, 30)' 'a[1]'\n",
    "50000000 loops, best of 5: 4.85 nsec per loop\n",
    "$python -m timeit -s 'a = [10, 20, 30]' 'a[1]'\n",
    "50000000 loops, best of 5: 4.6 nsec per loop\n",
    "\n",
    "$python -m timeit -s 'a = (10, 20, 30)' 'x, y, z = a'\n",
    "50000000 loops, best of 5: 5.43 nsec per loop\n",
    "$python -m timeit -s 'a = [10, 20, 30]' 'x, y, z = a'\n",
    "50000000 loops, best of 5: 5.66 nsec per loop\n",
    "\n",
    "$python -m timeit \"x=(1,2,3,4,5,6,7,8)\"\n",
    "50000000 loops, best of 5: 3.78 nsec per loop\n",
    "$python -m timeit \"x=[1,2,3,4,5,6,7,8]\"\n",
    "20000000 loops, best of 5: 16.4 nsec per loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back and explore how tuples can be used as records without field names. Tuples typically have a fixed number of items and their order matters. This makes them especially useful in situations where we can use unpacking to retrieve items from a tuple, and avoid the overhead of creating a class just to name the fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depart from São Paulo, 5:30 o'clock\n",
      "Depart from Bahia, 12:45 o'clock\n",
      "Depart from Pará, 14:50 o'clock\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('São Paulo', '5:30')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_order = [(\"São Paulo\", \"5:30\"), (\"Bahia\", \"12:45\"), (\"Pará\", \"14:50\")]\n",
    "\n",
    "for city, depart_time in flight_order:\n",
    "    print(f\"Depart from {city}, {depart_time} o'clock\")\n",
    "\n",
    "city, depart_time = flight_order[0]\n",
    "city, depart_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
