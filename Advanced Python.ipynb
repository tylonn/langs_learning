{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Python - Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Python Data Model\n",
    "The Python Data Model ensures the consistency of the language. It can be seen as a framework that formalizes the interfaces of the building blocks of Python. In other words, it is a collection of interfaces that define how Python's built-in behaviors and operations should interact with objects (through dunder methods).  \n",
    "When we code in Python, the interpreter invokes special methods to perform basic object operations based on a special syntax using double underscores (`__some_method__`) called dunder (`double under`) methods. When custom methods implement these protocols, they can behave as built-in types, and this is achieved thanks to operator overloading.\n",
    "All data in a Python program can be represented by objects or relations between objects, where data is encapsulated within objects. In a broader sense, an object is a collection of data and methods that act on the data. This allows for a higher level of abstraction, where the user can focus on the operations that can be performed with such objects rather than the internal implementation of data. These objects can interact with each other in various manners, such as passing messages or invoking methods. Python also treats code as objects. This is an important feature of high level languages when we think in a functional manner, because in this model functions can be treated as just another object.\n",
    "\n",
    "Each object in Python has an identity, a type and a value. It is important to note that an object's identity never changes once it has been created. This identity can be thought of as the memory address of the object. In this scenario, the `is` operator is the way to compare the identity of two objects instead of `==`. \n",
    "\n",
    "### ID\n",
    "The `id` function returns the memory address of an object and this value is unchangeable. The *id* sometimes is obtained through some optimizations, as listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139683335127408\n",
      "139683335127312\n",
      "139683335127312\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "first_value = 5\n",
    "print(id(first_value))\n",
    "\n",
    "second_value = 2\n",
    "print(id(second_value))\n",
    "\n",
    "third_value = 2\n",
    "print(id(third_value))\n",
    "\n",
    "print(first_value is second_value)\n",
    "print(second_value is third_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern observed above only refer to numbers between -5 and 256. This is because Python stores small integers in a cache due to performance reasons. In those cases, Python pre-allocates the integer objects created and reuses them as an attempt to save memory.\n",
    "When two variables are created and they have the same value, Python pre-allocates this value ensuring that both variables refers to the same object in memory. Whereas for values outside this range, Python allocates a new object in memory each time that an integer variable is created, as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2817949078032\n",
      "2817949078064\n",
      "2817949077968\n",
      "2817949078352\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "first_value = 256\n",
    "print(id(first_value))\n",
    "\n",
    "second_value = 256\n",
    "print(id(second_value))\n",
    "\n",
    "third_value = -5\n",
    "print(id(third_value))\n",
    "\n",
    "fourth_value = -5\n",
    "print(id(fourth_value))\n",
    "\n",
    "print(first_value is second_value)\n",
    "print(third_value is fourth_value)\n",
    "\n",
    "print(15 * \"-\")\n",
    "\n",
    "first_value = 257\n",
    "print(id(first_value))\n",
    "\n",
    "second_value = 257\n",
    "print(id(second_value))\n",
    "\n",
    "third_value = -6\n",
    "print(id(third_value))\n",
    "\n",
    "fourth_value = -6\n",
    "print(id(fourth_value))\n",
    "\n",
    "print(first_value is second_value)\n",
    "print(third_value is fourth_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This behavior extend in certain level to strings and do not is extended to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2817949077392\n",
      "2817949077360\n",
      "2817949076880\n",
      "2817949077328\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "first_value = 2.56\n",
    "print(id(first_value))\n",
    "\n",
    "second_value = 2.56\n",
    "print(id(second_value))\n",
    "\n",
    "third_value = -5.0\n",
    "print(id(third_value))\n",
    "\n",
    "fourth_value = -5.0\n",
    "print(id(fourth_value))\n",
    "\n",
    "print(first_value is second_value)\n",
    "print(third_value is fourth_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140002182303664\n",
      "140002182303664\n",
      "140002182303280\n",
      "140002182307952\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "first_value = \"Hello_world\"\n",
    "print(id(first_value))\n",
    "\n",
    "second_value = \"Hello_world\"\n",
    "print(id(second_value))\n",
    "\n",
    "third_value = \"Hello, world!\"\n",
    "print(id(third_value))\n",
    "\n",
    "fourth_value = \"Hello, world!\"\n",
    "print(id(fourth_value))\n",
    "\n",
    "print(first_value is second_value)\n",
    "print(third_value is fourth_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For strings, Python performs string interning selectively. This means that string literals that look like identifiers are typically interned automatically. Interning is a type of caching that applies to specific object instances and refers to Python reusing the string object instead of creating a new one every time the same string literal is used.\n",
    "\n",
    "In a broader sense, Python can perform some optimizations with immutable objects that may seem to have the same interning performed with integers and strings, but that are in fact actually compiler optimizations. In these optimizations, the interpreter understands that some immutable objects are the same if they are placed in different parts of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140002182175680\n",
      "140002182110016\n",
      "140002182123072\n",
      "140002182124416\n",
      "False\n",
      "False\n",
      "a is b? The answer is: True\n"
     ]
    }
   ],
   "source": [
    "first_value = (1, 2, 3)\n",
    "print(id(first_value))\n",
    "\n",
    "second_value = (1, 2, 3)\n",
    "print(id(second_value))\n",
    "\n",
    "third_value = {1, 2, 3}\n",
    "print(id(third_value))\n",
    "\n",
    "fourth_value = {1, 2, 3}\n",
    "print(id(fourth_value))\n",
    "\n",
    "print(first_value is second_value)\n",
    "print(third_value is fourth_value)\n",
    "\n",
    "\n",
    "# Optimizations occurs here:\n",
    "def test_id():\n",
    "    a = (1, 2, 3)\n",
    "    b = (1, 2, 3)\n",
    "    print(f\"a is b? The answer is: {a is b}\")\n",
    "\n",
    "\n",
    "test_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above optimization occurs only in the function namespace due to its restrictive nature. The function namespace is a confined and well-defined scope of code analysis. Therefore allowing the compiler to make some optimizations more aggressive when compared to its application at the global namespace (more unpredictable and dynamic).  \n",
    "\n",
    "The *id* function has some uses that are related to scenarios where the the managment of objects identities are necessary. This situations in general involves identifying duplicates, performing caching/memoizantion and implementing low-level optimizations. Although it has its uses, the *id* function is rarely applied in Python and has some specific use cases where it can be positively applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type  \n",
    "The object's type defines which operations can be applied to the object. It also defines the possible values that object of the referd type can have. The `type()` fucntion returns the type of a object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'list'>\n",
      "<class 'type'>\n",
      "<class 'type'>\n"
     ]
    }
   ],
   "source": [
    "a = 5\n",
    "print(type(a))\n",
    "b = [1, 2, 3]\n",
    "print(type(b))\n",
    "print(type(type))\n",
    "print(type(object))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `type` object is a metaclass and also a function which returns the type of a object. In this sense, `type` is an instace of itself, which forms a recursive loop and can also be considered the foundational class of the Python language, because it its the class which all other classes are derived from, directly or indirectly.  \n",
    "This self-referential characteristic of the `type` metaclass is what allow it to act as a sort of a foundation for all classes. Python allow us to create metaclasses for our classes. These metaclasses are also derived from the `type` class.  \n",
    "\n",
    "Although different from the base class, is important noting that `type` is the default metaclass in Python which defines how a class behaves, allowing the customization of class creation, modification and deletion, furthermore it also can be thought of as classes of classes (a class is a instace of it metaclass). Im this context, every class in Python is is an instance of `type` even itself.  \n",
    "The base class is the one inherited by another class. In Python the `object` class is the one inherited by all new-style classes (with all its attributes and methods).  \n",
    "\n",
    "Besides getting the type of a object, the `type` function can be used to create a class dynamically:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "25\n",
      "5\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "MyDynamicClass = type(\n",
    "    \"MyDynamicClass\", (object,), {\"x\": 5, \"y\": 10, \"z\": staticmethod(lambda x: x * x)}\n",
    ")\n",
    "print(MyDynamicClass.x)\n",
    "print(MyDynamicClass.z(5))\n",
    "\n",
    "instance = MyDynamicClass()\n",
    "print(instance.x)\n",
    "print(instance.z(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of dynamic created classes follows a clear pattern that is mostly suited to situatios when the properties, methods, or base classes of the objects of one's code are determined by external factors that are only known at runtime, such as user input, configuration data, or external schemas. This approach fits properly in scenarios where static class creation would lead to escessive code duplication or complexity.  \n",
    "A helpful way of thinking in terms of using this approach is to evaluate if the behavior of a class is dependent on conditions only known at runtime, requires class generation/modification dynammically, aims to avoid code duplication, or allows end users to modify/extend the system without altering the core codebase.   \n",
    "Although very useful in certain situations, the use of type in this manner adds a significant level of complexity to the code, necessitating its use to be always well-considered and keeping in mind the possible trade-offs.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some use cases that cover the vast majority of situations where creating a class dynamically could be helpful. One such use case is when there's a requirement to create a class at runtime that should contain type hints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.SubClass"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Type, cast\n",
    "\n",
    "\n",
    "class BaseClass:\n",
    "    pass\n",
    "\n",
    "\n",
    "# The cast function cast a value to a type, returning it unchanged. It is only useful for type-checkers\n",
    "# because it signals that the type has the designated value.\n",
    "cast(Type[BaseClass], type(\"SubClass\", (BaseClass,), {}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to create class dynamically with slots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<member 'a' of 'MyClass' objects>\n"
     ]
    }
   ],
   "source": [
    "MyClass = type(\"MyClass\", (), {\"__slots__\": (\"a\", \"b\")})\n",
    "print(MyClass.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slots allow for the explicit specification of which instance attributes an object is expected to have. This results in faster attribute access and reduced memory usage. The memory savings occur because instances do not use a dynamic dictionary for attribute storage; instead, they use a fixed-sized array, which is less memory-intensive than a dictionary. Additionally, accessing attributes stored in `__slots__` follows a more direct memory access pattern, resulting in less indirection compared to a dictionary. Moreover, using `__slots__` ensures that instances cannot access attributes not listed in it.\n",
    "\n",
    "It's worth mentioning that dynamic attribute assignment is still possible when using slots, although some of the memory size benefits are lost. This can be achieved by including `\"__dict__\"` in the `__slots__` definition, allowing for dynamic attributes in addition to those specified. The use of slots requires careful consideration due to the changes in class behavior it introduces.\n",
    "\n",
    "More information about __slots__ can be found [here](https://stackoverflow.com/questions/472000/usage-of-slots).  \n",
    "\n",
    "It is also possible to pass dunder methods dynamically (as seen above) to classes created dynamically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 and A\n"
     ]
    }
   ],
   "source": [
    "def init(self):\n",
    "    self.x = 5\n",
    "    self.y = \"A\"\n",
    "    \n",
    "MyClass = type(\"MyClass\", (), {\"__init__\": init})\n",
    "\n",
    "my_instance = MyClass()\n",
    "print(f\"{my_instance.x} and {my_instance.y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another pattern that could be useful is to create a class factory to generate classes automatically:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 and B\n"
     ]
    }
   ],
   "source": [
    "def class_builder(cls_name=\"MyClass\"):\n",
    "    # NOTE: it is possible to add a arg that map base classes\n",
    "    def init(self):\n",
    "        self.x = 25\n",
    "        self.y = \"B\"\n",
    "        \n",
    "    return type(cls_name, (), {\"__init__\": init})\n",
    "\n",
    "\n",
    "MyClass = class_builder()\n",
    "my_instance = MyClass()\n",
    "print(f\"{my_instance.x} and {my_instance.y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of pattern is useful for serialization and deserialiaztion of objects. The use of this type of pattern in general also follows the recommendations mentioned previously, spetially in situations where the data is known only at runtime, as mentioned [here](https://ctskennerton.github.io/2021/11/24/dynamic-types-in-python./)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another situation that is useful being aware of is the possibility for passing default arguments to a subclass created dynamically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subclass created and my name is John\n"
     ]
    }
   ],
   "source": [
    "class BaseClass:\n",
    "    def __init_subclass__(cls, my_name):\n",
    "        print(f\"Subclass created and my name is {my_name}\")\n",
    "        # super().__init_subclass__() Needed only in case of multiple inheritance\n",
    "\n",
    "MyDynamicSubClass = type(\"MyDynamicSubClass\", (BaseClass,), {}, my_name=\"John\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When is this pattern useful?\n",
    "\n",
    " - Runtime Configuration: When specific information is only available at runtime, allowing for dynamic class creation and customization.\n",
    "- Validation and Registration: For implementing checks and registering instances to ensure data integrity and uniqueness.\n",
    "- Default Data Provision: To pre-populate subclasses with relevant data based on their specific type or context.  \n",
    "\n",
    "Further information about `__init_subclass__` can be found [here](https://stackoverflow.com/questions/63473901/python-dynamically-create-class-while-providing-arguments-to-init-subclass)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another pattern useful for dynamic class creation from containers, like JSON, is to use a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burger with attributes {'aka': ['cheeseburger', 'hamburger']}\n",
      "fries with attributes {'aka': ['french fries', 'potatoes']}\n",
      "meal with attributes {'items': [{'name': 'burger', 'value': '<burger>'}, {'name': 'fries', 'value': '<fries>'}]}\n"
     ]
    }
   ],
   "source": [
    "my_json = {\n",
    "\"stuff\": [{\n",
    "        \"name\": \"burger\",\n",
    "        \"aka\": [\"cheeseburger\", \"hamburger\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"fries\",\n",
    "        \"aka\": [\"french fries\", \"potatoes\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"meal\",\n",
    "        \"items\": [{\n",
    "                \"name\": \"burger\",\n",
    "                \"value\": \"<burger>\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"fries\",\n",
    "                \"value\": \"<fries>\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "  ]\n",
    "}\n",
    "\n",
    "class MenuItem:\n",
    "\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__} with attributes {self.__dict__}\"\n",
    "\n",
    "for d in my_json[\"stuff\"]:\n",
    "    name = d.pop(\"name\")\n",
    "    NewClass = type(name, (MenuItem,), d)\n",
    "    print(NewClass(**d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, type hints may be required during dynamic class creation. In sistuations like this the best approach is to leverage the use of duncer methods in association with the `type` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Some string', {'some_field': str})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_hints = {\"some_field\": str}\n",
    "MyClass = type('MyClass', (), {\"__doc__\": \"Class created dynamically\",\n",
    "                               \"__annotations__\": type_hints,\n",
    "                               \"some_field\": \"Some string\"})\n",
    "new_instace = MyClass()\n",
    "new_instace.some_field, new_instace.__annotations__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beside the `type` function, Python also has as an alternative to class creation the `types.new_class` function. The class creation process through `types.new_class` is signficantly more flexible when compared to the base `type` as it provides a mechanism for directly dealing with metaclasses and also allows a `exec_body` to be executed in the namespace of the class being created. More about the use of this approach can be found [here](https://docs.python.org/3/library/types.html#dynamic-type-creation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value\n",
    "The value of a object can change or not. This capabilitie defines if a object is mutable or immutable. But immutability is a tricky concept because a immutable object can have a reference to a mutable one. So, in this scenario, the value of a immutable object `can change` when the mutable object its referes to change. In this sense immutability is different from having a unchangeable value. Altough, the `id` of the object do not tend to change, at least in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, [1, 2, 256])\n",
      "8893480\n",
      "140518044983424\n",
      "140518044832640\n",
      "(1, 2, [1, 2, (5545, 'my tuple')])\n",
      "140518079995392\n",
      "140518044983424\n",
      "140518044832640\n"
     ]
    }
   ],
   "source": [
    "num = 256\n",
    "lst = [1, 2, num]\n",
    "tpl = (1, 2, lst)\n",
    "print(tpl)\n",
    "print(id(num))\n",
    "print(id(lst))\n",
    "print(id(tpl))\n",
    "num = (5545, \"my tuple\")\n",
    "lst[2] = num\n",
    "print(tpl)\n",
    "print(id(num))\n",
    "print(id(lst))\n",
    "print(id(tpl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, the `id`s of lst and tpl did not changed because when a object is created in Python its id remains the same even after altering the value it is refering to.  \n",
    "One other important thing is that, for immutable types, operations that compute a new value may actually return a reference to any existing object `a = 1; b = 1` where a and b may referes to the same object, but in `c = []; d = []` is guaranteed that c and d refers to different objects.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structures\n",
    "The built-in Python sequences can be summarized as Container Sequences and Flat Sequences. The difference between these two is that the first one can hold items of different types while the former only can hold values that are from the same type.  \n",
    "In general, Flat Sequences are more compact altough they have the limitation to only holding primitive types.  \n",
    "Every python object has a metadata header with at least three fields:   \n",
    "- on_refcnt   \n",
    "- ob_type   \n",
    "- ob_val  \n",
    " \n",
    "And each one of these fields take 8 bytes. For this reason a array is more compact than a tuple, for example: the array is a single object holding the raw values of its items while the tuple consists of several objects (the tuple itself and each object contained in it). Another important item related to tuples and their comparisson with lists can re read [here](https://stackoverflow.com/questions/68630/are-tuples-more-efficient-than-lists-in-python).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0           0 RESUME                   0\n",
      "\n",
      "  1           2 PUSH_NULL\n",
      "              4 LOAD_NAME                0 (tuple)\n",
      "              6 BUILD_LIST               0\n",
      "              8 LOAD_CONST               0 ((1.5, 2.1, 3.8))\n",
      "             10 LIST_EXTEND              1\n",
      "             12 CALL                     1\n",
      "             20 POP_TOP\n",
      "             22 RETURN_CONST             1 (None)\n",
      "getsizeof: 64\n",
      "asizeof: 136\n",
      "__________________________________________________\n",
      "                                                  \n",
      "  0           0 RESUME                   0\n",
      "\n",
      "  1           2 LOAD_NAME                0 (array)\n",
      "              4 LOAD_ATTR                1 (NULL|self + array)\n",
      "             24 LOAD_CONST               0 ('d')\n",
      "             26 BUILD_LIST               0\n",
      "             28 LOAD_CONST               1 ((1.5, 2.1, 3.8))\n",
      "             30 LIST_EXTEND              1\n",
      "             32 CALL                     2\n",
      "             40 POP_TOP\n",
      "             42 RETURN_CONST             2 (None)\n",
      "getsizeof: 104\n",
      "asizeof: 104\n"
     ]
    }
   ],
   "source": [
    "import dis\n",
    "import sys\n",
    "import array\n",
    "from pympler import asizeof\n",
    "\n",
    "tpl = compile(\"tuple([1.5, 2.1, 3.8])\", \"\", \"exec\")\n",
    "dis.dis(tpl)\n",
    "print(f\"getsizeof: {sys.getsizeof(tuple([1.5, 2.1, 3.8]))}\")\n",
    "print(f\"asizeof: {asizeof.asizeof(tuple([1.5, 2.1, 3.8]))}\")\n",
    "\n",
    "print(50 * \"_\")\n",
    "print(50 * \" \")\n",
    "\n",
    "arr = compile('array.array(\"d\", [1.5, 2.1, 3.8])', \"\", \"exec\")\n",
    "dis.dis(arr)\n",
    "print(f'getsizeof: {sys.getsizeof(array.array(\"d\", [1.5, 2.1, 3.8]))}')\n",
    "print(f'asizeof: {asizeof.asizeof(array.array(\"d\", [1.5, 2.1, 3.8]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code we used two ways of calculating the size of a python object. `getsizeof` returns the size of the object passed to it only whereas `asizeof` returns the size of the object passed to it but also the objects referenced within the complex object instance.   \n",
    "In general, `getsizeof` only reports the raw memory allocated (header and its immediate contents) for the list's data and it is based on the interpreter's internal calculations.  \n",
    "`asizeof` does that by recursively adding up the sizes of all objects after traversing the object contents and examining the object attributes. `asizeof` also avoids calculating the size of the same object twice, in the case of this object be referenced more than once, by keeping tracking of the objcets IDs that it already visited by using a `set` or something a similar mechanism that allow it to recognize already-measured objects. It is important to note that it uses `getsizeof` to measure the size of the objects encountered and also take account of the extra space allocated by containers objects since some Python objects have over-allocation to amortized append operations, furthermore it also is capable of detecting shared objects, such as objects that are instances of classes with `__slots__` or some interned objects like strings. Although very useful, `asizeof` returns the estimated size of the objects plus all of it referents (_referents_ are objects acessible from the parent object according tho the traversal of its attributes and contents).  \n",
    "In summary, `asizeof` does the following:  \n",
    "1 - Indentify the object type;  \n",
    "2 - Consult a pre-defined table with estimated base sizes for different object types;  \n",
    "3 - Evaluate the content and (a) if applicable, recursively iterate through the object contents or/and (b) for each element, repeat the steps 1-3 to estimate the size and accumulate it to the total;  \n",
    "4 - Keeps track of objects by analyzing internal references within the parent objects and adds the contribution for referenced objects (avoidind double counting);  \n",
    "5 - Apply additional estimations for header infos and garbage collection, while avoiding double counting;  \n",
    "6 - Returns the summed up size of the traversed object.   \n",
    "\n",
    "Another way to think about collections in Python is comparing Mutable and Immutable objects. The difference between them is clear, but it's worth mentioning that Mutable sequences inherit all the Immutable sequences' methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists, Tulpes, Dictionaries, Sets and, Generators\n",
    "Python has some common use builtins containers types that are very handy and has a wide variety of use cases in general. The first of them and perhaps the most used also are lists. They are present in pretty much everything that python touches due to its versatility. A nice example is list comprehensions, that can be used for a wide range of situations. Two nice patterns for using lists are for \"replacing\" map and filter, and for cartesian products, as demonstrated bellow. The use of list comprehensions is a neat approach to reduce code complexity and also can be very useful when delaig with sorted lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Urophylla', 80), ('Urophylla', 90), ('Urophylla', 89), ('Urophylla', 99), ('Urophylla', 95), ('Camaldulensis', 80), ('Camaldulensis', 90), ('Camaldulensis', 89), ('Camaldulensis', 99), ('Camaldulensis', 95), ('Citriodora', 80), ('Citriodora', 90), ('Citriodora', 89), ('Citriodora', 99), ('Citriodora', 95), ('Globulus', 80), ('Globulus', 90), ('Globulus', 89), ('Globulus', 99), ('Globulus', 95)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Urophylla', 99),\n",
       " ('Camaldulensis', 99),\n",
       " ('Citriodora', 99),\n",
       " ('Globulus', 99),\n",
       " ('Urophylla', 95),\n",
       " ('Camaldulensis', 95),\n",
       " ('Citriodora', 95),\n",
       " ('Globulus', 95),\n",
       " ('Urophylla', 90),\n",
       " ('Camaldulensis', 90),\n",
       " ('Citriodora', 90),\n",
       " ('Globulus', 90),\n",
       " ('Urophylla', 89),\n",
       " ('Camaldulensis', 89),\n",
       " ('Citriodora', 89),\n",
       " ('Globulus', 89),\n",
       " ('Urophylla', 80),\n",
       " ('Camaldulensis', 80),\n",
       " ('Citriodora', 80),\n",
       " ('Globulus', 80)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = [\"Urophylla\", \"Camaldulensis\", \"Citriodora\", \"Globulus\"]\n",
    "models = [80, 90, 89, 99, 95]\n",
    "\n",
    "print([(specie, model) for specie in species for model in models])\n",
    "sorted([(specie, model) for specie in species for model in models], key=lambda model: model[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A option to lists are generators expressions. Their use is of significant advantage when one aims to reduce memory use or has some memory intensive data collection. The approach that generators use is fairly simple yet very powerfull: it does not produce any value if not upon request. In other words, a generator expression simple do not return the collection of data although it produces these items. The \"forcing\" of item production arises from the use of some features like loops, colelctions contruction and calling `next` on the generator object, thought is necessary to warns that the once the generator object is used its content are nor available anymore, as a result the error `StopIteration` is raised when all its items are consumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x7f4c34356dc0>\n",
      "Urophylla yeilds the score: 80\n",
      "Urophylla yeilds the score: 90\n",
      "Urophylla yeilds the score: 89\n",
      "Urophylla yeilds the score: 99\n",
      "Urophylla yeilds the score: 95\n",
      "Camaldulensis yeilds the score: 80\n",
      "Camaldulensis yeilds the score: 90\n",
      "Camaldulensis yeilds the score: 89\n",
      "Camaldulensis yeilds the score: 99\n",
      "Camaldulensis yeilds the score: 95\n",
      "Citriodora yeilds the score: 80\n",
      "Citriodora yeilds the score: 90\n",
      "Citriodora yeilds the score: 89\n",
      "Citriodora yeilds the score: 99\n",
      "Citriodora yeilds the score: 95\n",
      "Globulus yeilds the score: 80\n",
      "Globulus yeilds the score: 90\n",
      "Globulus yeilds the score: 89\n",
      "Globulus yeilds the score: 99\n",
      "Globulus yeilds the score: 95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Urophylla yeilds the score: 80',\n",
       " 'Urophylla yeilds the score: 90',\n",
       " 'Urophylla yeilds the score: 89',\n",
       " 'Urophylla yeilds the score: 99',\n",
       " 'Urophylla yeilds the score: 95',\n",
       " 'Camaldulensis yeilds the score: 80',\n",
       " 'Camaldulensis yeilds the score: 90',\n",
       " 'Camaldulensis yeilds the score: 89',\n",
       " 'Camaldulensis yeilds the score: 99',\n",
       " 'Camaldulensis yeilds the score: 95',\n",
       " 'Citriodora yeilds the score: 80',\n",
       " 'Citriodora yeilds the score: 90',\n",
       " 'Citriodora yeilds the score: 89',\n",
       " 'Citriodora yeilds the score: 99',\n",
       " 'Citriodora yeilds the score: 95',\n",
       " 'Globulus yeilds the score: 80',\n",
       " 'Globulus yeilds the score: 90',\n",
       " 'Globulus yeilds the score: 89',\n",
       " 'Globulus yeilds the score: 99',\n",
       " 'Globulus yeilds the score: 95']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = [\"Urophylla\", \"Camaldulensis\", \"Citriodora\", \"Globulus\"]\n",
    "models = [80, 90, 89, 99, 95]\n",
    "\n",
    "model_ranking = (f\"{specie} yeilds the score: {model}\" for specie in species for model in models)\n",
    "# We see that this object is a generator object\n",
    "print(model_ranking)\n",
    "\n",
    "# Consuming the genexp\n",
    "for i in model_ranking:\n",
    "    print(i)\n",
    "\n",
    "# Crteates a list from a generator expression\n",
    "list((f\"{specie} yeilds the score: {model}\" for specie in species for model in models))\n",
    "\n",
    "# A error arrisen when trying to use a generator object after the consuption of its items\n",
    "# next(model_ranking) raises StopIteration error\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
